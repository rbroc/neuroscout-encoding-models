{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge regression workflow for Neuroscout\n",
    "\n",
    "This notebook implements a cross-valided voxel-wise encoding model for a single subject using Regularized Ridge Regression.\n",
    "\n",
    "The goal is to demonstrate how to obtain Neuroscout data to fit models using custom pipelines. For a comprehensive tutorial, check out the excellent [voxelwise modeling tutorials](https://gallantlab.github.io/voxelwise_tutorials/index.html) from the Gallant Lab.\n",
    "\n",
    "__Note__: By implementing a custom pipeline, your analysis will not be centrally registered on neuroscout.org, and a reproducible record will not be made. For analyses supported the Neuroscout-CLI (e.g. group voxel-wise mass univariate GLM models), it is recommended to use the neuroscout.org web inteface, or follow the guide for programmatically [creating analyses \n",
    "using pyNS](https://pyns.readthedocs.io/en/latest/analyses.html).\n",
    "\n",
    "### Citing Neuroscout\n",
    "\n",
    "If you publish any results using the Neuroscout data, be sure to cite the Neuroscout paper, and corresponding datasets:\n",
    "\n",
    "    Alejandro de la Vega, Roberta Rocca, Ross W Blair, Christopher J Markiewicz, Jeff Mentch, James D Kent, Peer Herholz, Satrajit S Ghosh, Russell A Poldrack, Tal Yarkoni (2022). *Neuroscout, a unified platform for generalizable and reproducible fMRI research*. eLife 11:e79277. https://doi.org/10.7554/eLife.79277\n",
    "    \n",
    "    Visconti di Oleggio Castello, M., Chauhan, V., Jiahui, G., & Gobbini, M. I. An fMRI dataset in response to “The Grand Budapest Hotel”, a socially-rich, naturalistic movie. Sci Data 7, 383 (2020). https://doi.org/10.1038/s41597-020-00735-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching Neuroscout Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily retrieve data from _Neuroscout_ using __pyNS__-- the Python Neuroscout API client.\n",
    "Be sure to refer to the official [pyNS documentation](https://pyns.readthedocs.io/en/latest/) for further usage information, with particular focus on the section on [fetching predictors and images](https://pyns.readthedocs.io/en/latest/fetching.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What data is available?\n",
    "\n",
    "If you're not sure what is available, you can browse Neuroscout's [datasets](https://neuroscout.org/datasets) and [predictors](https://neuroscout.org/predictors) online.\n",
    "\n",
    "Here, we were going to focus on the 'Budapest' dataset, choosing the first subject (`sid000005`) as an example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acquisition': None,\n",
       " 'dataset_id': 27,\n",
       " 'duration': 598.0,\n",
       " 'id': 1438,\n",
       " 'number': 1,\n",
       " 'session': None,\n",
       " 'subject': 'sid000007',\n",
       " 'task': 48,\n",
       " 'task_name': 'movie'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find first subject for Budapest\n",
    "from pyns import Neuroscout\n",
    "\n",
    "api = Neuroscout()\n",
    "\n",
    "dataset_name = 'Budapest'\n",
    "\n",
    "# First run for Budapest dataset\n",
    "first_run = api.runs.get(dataset_name=dataset_name)[5]\n",
    "subject = first_run['subject'] # Save subject name\n",
    "\n",
    "first_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching predictors \n",
    "\n",
    "We will fetch two sets of predictors: [Mel spetrogram](https://neuroscout.org/predictor/mel_0), and  [Mel Frequency Cepstral Coefficient (MFCC)](https://neuroscout.org/predictor/mfcc_0). Both of these features are extracted from the auditory track of the movie stimulus ('The Grand Budapest Hotel'). Later in the tutorial we'll fit an encoding model to each set of features separately, and then jointly using a banded model.\n",
    "\n",
    "First, we define the names of the predictors we will fetch. \n",
    "\n",
    "To learn more about basic Neuroscout API querying, see this [guide](https://pyns.readthedocs.io/en/latest/querying.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs = [f'mfcc_{i}' for i in range(20)]\n",
    "mel = [f'mel_{i}' for i in range(64)]\n",
    "\n",
    "confounds = ['rot_x', 'rot_y', 'rot_z', 'trans_x', 'trans_y', 'trans_z',\n",
    "             'a_comp_cor_00', 'a_comp_cor_01', 'a_comp_cor_02',\n",
    "             'a_comp_cor_03','a_comp_cor_04','a_comp_cor_05']\n",
    "\n",
    "all_vars = mfccs + mel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can use the high-level utility `fetch_predictors` to retrieve these predictors for the target subject, rescaled using unit variance, and resampled to the imaging data's Repetition Time (TR):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results in a dataframe with predictors, plus meta-data such as file entities (e.g. subjects, runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch fMRI data and loading images\n",
    "\n",
    "To retrieve Neuroscout data, we use `datalad` to fetch the preprocessed images remote.\n",
    "pyNS includes a helper function to facilitate installing and fetching the dataset using datalad: `fetch_images`.\n",
    "\n",
    "Provide the name of the dataset (`Budapest`), plus a directory where your datasets are stored, plus (optionally) filters to restrict which files are downloaded (e.g. subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alejandro/miniconda3/envs/nsencoding/lib/python3.10/site-packages/bids/layout/validation.py:51: UserWarning: The ability to pass arguments to BIDSLayout that control indexing is likely to be removed in future; possibly as early as PyBIDS 0.14. This includes the `config_filename`, `ignore`, `force_index`, and `index_metadata` arguments. The recommended usage pattern is to initialize a new BIDSLayoutIndexer with these arguments, and pass it to the BIDSLayout via the `indexer` argument.\n",
      "  warnings.warn(\"The ability to pass arguments to BIDSLayout that control \"\n",
      "/home/alejandro/miniconda3/envs/nsencoding/lib/python3.10/site-packages/bids/layout/validation.py:156: UserWarning: The PipelineDescription field was superseded by GeneratedBy in BIDS 1.4.0. You can use ``pybids upgrade`` to update your derivative dataset.\n",
      "  warnings.warn(\"The PipelineDescription field was superseded \"\n"
     ]
    }
   ],
   "source": [
    "from pyns.fetch_utils import fetch_images\n",
    "\n",
    "preproc_dir, img_objs = fetch_images('Budapest', '/tmp/', subject=subject, fetch_brain_mask=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fetch_images` represents images as pybids `BIDSImageFile` objects, which include meta-data such as entities as part of the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_objs[5].get_entities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the entities, we can separate the list of images into two lists: preprocessed functional images, and brain masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_funcs = [f for f in img_objs if f.entities['suffix'] == 'bold']\n",
    "all_masks = [f for f in img_objs if f.entities['suffix'] == 'mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following computes a joint mask for all runs. Alternatively, we could also provide a apriori ROI mask here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply the corresponding brain mask to each run using `NiftiMasker` from `nilearn`, and stack them into a single array for subsequent analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nilearn.maskers import NiftiMasker\n",
    "\n",
    "def _mask_and_stack_images(image_objects, mask):\n",
    "    \"\"\" Stack images into single array, and collect metadata entities into dataframe \"\"\"\n",
    "    masker = NiftiMasker(mask_img=mask)\n",
    "\n",
    "    arrays = []\n",
    "    entities = []\n",
    "    image_objects = sorted(image_objects, key=lambda x: x.entities['run'])\n",
    "    for img in image_objects:\n",
    "        run_y = masker.fit_transform(img)\n",
    "        arrays.append(run_y)\n",
    "        entities += [dict(img.entities)] * run_y.shape[0]\n",
    "    entities = pd.DataFrame(entities)\n",
    "    return np.vstack(arrays), entities, masker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, img_entities, masker = _mask_and_stack_images(all_funcs, inter_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stacked runs have shape: (n_volumes, n_voxels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also keep the entities associated with each volume in a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Ridge regression model using melspectrogram features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll fit a basic Ridge regression model to a subset of voxels (for demonstration purposes).\n",
    "\n",
    "We'll define two cross-validators: an outer and an inner cv. The outer cross-validator will loop be used to estimate the performance of the model on unseen data, and the inner cv will be used to select the alpha hyperparameter for Ridge regression, within each fold of the outer cross-validator.\n",
    "\n",
    "In both cases, we'll use the leave-one-run-out strategy, testing the model on an unseen run. Since there are multiple observations per run, we use the`run` column of `X_entities` to group observations, and ensure they appear together within each fold.\n",
    "\n",
    "Finally, we also define a scoring function, in this case, `correlation_score`.\n",
    "\n",
    "Note that we are using the `himalaya` library's `KernelRidgeCV` estimator, as it is optimized for multi-target (i.e. voxel) estimation & hyperparameter optimization with a sklearn-like API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from himalaya.ridge import RidgeCV\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from himalaya.scoring import correlation_score\n",
    "from himalaya.backend import set_backend\n",
    "\n",
    "# backend = set_backend(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a generic pipeline for applying the esimator to the data (including support for banded-regression, which we'll discuss later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _model_cv(estimator, cv, X_vars, y, bands=None, groups=None,\n",
    "              scoring=correlation_score,\n",
    "              inner_cv=None, confounds=None, split=None):\n",
    "    \n",
    "    # Container for results\n",
    "    results = {\n",
    "        'coefficients': [],\n",
    "        'test_predictions': [],\n",
    "        'test_scores': []}\n",
    "\n",
    "    \n",
    "    if bands is not None:\n",
    "        X = []\n",
    "        for band in bands:\n",
    "            X.append(X_vars[band].values)\n",
    "    else:\n",
    "        X = X_vars.values\n",
    "        \n",
    "    n_confounds = confounds.shape[1] if confounds is not None else 0\n",
    "    \n",
    "    # If confounds, stack at the end\n",
    "    if confounds is not None:\n",
    "        X = X + [confounds] if type(X) == list else np.hstack((X, confounds))\n",
    "    \n",
    "    # Extract number of samples for convenience\n",
    "    n_samples = y.shape[0]\n",
    "    \n",
    "    # Loop through outer cross-validation folds\n",
    "    for train, test in cv.split(np.arange(n_samples), groups=groups):\n",
    "        \n",
    "        # Get training model for list of model bands\n",
    "        X_train = [x[train] for x in X] if type(X) == list else X[train]\n",
    "        X_test = [x[test] for x in X] if type(X) == list else X[test]\n",
    "        \n",
    "        # Create inner cross-validation loop if specified\n",
    "        if inner_cv:\n",
    "            # Split inner cross-validation with groups if supplied\n",
    "            inner_groups = np.array(groups)[train] if groups else groups\n",
    "            inner_splits = inner_cv.split(np.arange(n_samples)[train],\n",
    "                                          groups=inner_groups)\n",
    "            \n",
    "            # Update estimator with inner cross-validator\n",
    "            estimator.set_params(cv=inner_splits)\n",
    "        \n",
    "        # Fit the regression model on training data\n",
    "        estimator.fit(X_train, y[train])\n",
    "        \n",
    "        # Zero out coefficients for confounds if provided\n",
    "        if confounds is not None:\n",
    "            estimator.coef_[-n_confounds:] = 0\n",
    "        \n",
    "        # Compute predictions with optional splitting by band\n",
    "        kwargs = {}\n",
    "        if split is not None:\n",
    "            kwargs['split'] = split\n",
    "            \n",
    "        test_prediction = estimator.predict(X_test, **kwargs)\n",
    "        \n",
    "        # Test scores should also optionally split by band\n",
    "        test_score = scoring(y[test], test_prediction)\n",
    "        \n",
    "        # Populate results dictionary\n",
    "#         results['coefficients'].append(estimator.dual_coef_)\n",
    "        results['test_predictions'].append(test_prediction)\n",
    "        results['test_scores'].append(test_score)\n",
    "        \n",
    "    # Combine into single aray\n",
    "#     results['coefficients'] = np.stack(results['coefficients'])\n",
    "    results['test_scores'] = np.stack(results['test_scores'])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finite impulse response model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the hemodynamic response lag, it's likely the model would perform better if the predictors were delayed.\n",
    "\n",
    "We can do so using a Finite Impulse Response (fir) model. \n",
    "\n",
    "Using `fetch_predictors`, we can ask for the predictors to be returned as a `BIDSVariableCollection`, which enables us to apply any of the transformations implemented in pybids. \n",
    "\n",
    "Alternatively, you could apply any arbitrary transformations, by requesting a pandas data-frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pyns.fetch_utils import fetch_predictors\n",
    "\n",
    "collection = fetch_predictors(all_vars + confounds, dataset_name='Budapest', subject='sid000007', \n",
    "                              resample=True, return_type='collection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(collection, open('ohbm_results/Budapest_sid000005_mel_mfcc_collection.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection = pickle.load(open('ohbm_results/Budapest_sid000005_mel_mfcc_collection.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use `Convolve` to apply a `fir` model, and `Scale` to ensure the final predictors have a mean of zero, and finally convert to a pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bids.modeling.transformations import Convolve, Scale\n",
    "\n",
    "def _fir_scale_df(collection, predictor_names):    \n",
    "    Convolve(collection, predictor_names, model='fir', fir_delays=[1, 2, 3, 4])\n",
    "    \n",
    "    all_vars = list(collection.variables.keys())\n",
    "    \n",
    "    Scale(collection, predictor_names, demean=True, rescale=False)\n",
    "\n",
    "    # To df, and sort rows by keys\n",
    "    collection_df = collection.to_df().sort_values(['subject', 'run', 'onset'])\n",
    "\n",
    "    # Reorder columns\n",
    "    sort_columns = ['onset', 'duration'] + predictor_names\n",
    "    sort_columns += collection_df.columns.difference(sort_columns).tolist()\n",
    "    collection_df = collection_df[sort_columns]\n",
    "    \n",
    "    return collection_df\n",
    "\n",
    "collection_df = _fir_scale_df(collection, all_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up estimator and CV objects\n",
    "estimator = RidgeCV()\n",
    "\n",
    "groups = collection_df['run'].tolist()\n",
    "n_runs = len(set(groups))\n",
    "cv = GroupKFold(n_splits=n_runs)\n",
    "inner_cv = GroupKFold(n_splits=n_runs - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FIR convolution results in 5x amount of predictors, including the delayed version of the predictors.\n",
    "\n",
    "We can now fit a model with all the mel-spectrogram features, to see if that improves prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = collection_df.iloc[:, collection_df.columns.str.startswith('mel')]\n",
    "confounds_X = collection_df[confounds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_mel_fir = _model_cv(estimator, cv, X, y, inner_cv=inner_cv, groups=groups, confounds=confounds_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_scores_mel_fir = results_mel_fir['test_scores'].mean(axis=0)\n",
    "mean_scores_mel_fir[mean_scores_mel_fir < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The max score increases, while the mean score remains similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_scores_mel_fir.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_scores_mel_fir.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stat_map(masker.inverse_transform(mean_scores_mel_fir), display_mode='z', threshold=0.075, vmax=0.35, cut_coords=[-23, -6, 11, 24, 39])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIR model with MFCC features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = collection_df.iloc[:, collection_df.columns.str.startswith('mfcc')]\n",
    "results_mfcc_fir = _model_cv(estimator, cv, X, y, inner_cv=inner_cv, groups=groups, confounds=confounds_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_mfcc_fir = results_mfcc_fir['test_scores'].mean(axis=0)\n",
    "results_mfcc_fir[results_mfcc_fir < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_mfcc_fir.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_mfcc_fir.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stat_map(masker.inverse_transform(results_mfcc_fir), display_mode='z', threshold=0.075, vmax=0.35, cut_coords=[-23, -6, 11, 24, 39])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Banded model with both mel and MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from himalaya.kernel_ridge import MultipleKernelRidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator = MultipleKernelRidgeCV()\n",
    "X = collection_df.iloc[:, collection_df.columns.str.startswith('m')]\n",
    "\n",
    "results_combined = _model_cv(estimator, cv, X, y, inner_cv=inner_cv, groups=groups, confounds=confounds_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_combined = results_combined['test_scores'].mean(axis=0)\n",
    "results_combined[results_combined < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_combined.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_combined.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stat_map(masker.inverse_transform(results_combined), display_mode='z', threshold=0.075, vmax=0.35, cut_coords=[-23, -6, 11, 24, 39])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple RMS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_collection = fetch_predictors(['rms'], dataset_name='Budapest', subject='sid000005', \n",
    "                              resample=True, return_type='collection')\n",
    "rms_collection_df = _fir_scale_df(rms_collection, ['rms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rms_collection_df.iloc[:, rms_collection_df.columns.str.startswith('r')]\n",
    "\n",
    "rms_results = _model_cv(estimator, cv, X, y, inner_cv=inner_cv, groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_results_combined = rms_results['test_scores'].mean(axis=0)\n",
    "rms_results_combined[rms_results_combined < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stat_map(masker.inverse_transform(rms_results_combined), display_mode='z', threshold=0.05, cut_coords=[-23, -6, 2, 11, 24, 39])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_collection = fetch_predictors(['speech'], dataset_name='Budapest', subject='sid000005', \n",
    "                              resample=True, return_type='collection')\n",
    "speech_collection = _fir_scale_df(speech_collection, ['speech'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = speech_collection.iloc[:, speech_collection.columns.str.startswith('spee')]\n",
    "\n",
    "speech_results = _model_cv(estimator, cv, X, y, inner_cv=inner_cv, groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_results = speech_results['test_scores'].mean(axis=0)\n",
    "speech_results[speech_results < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_stat_map' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_stat_map\u001b[49m(masker\u001b[38;5;241m.\u001b[39minverse_transform(speech_results), display_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m, threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m, cut_coords\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m23\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m24\u001b[39m, \u001b[38;5;241m39\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_stat_map' is not defined"
     ]
    }
   ],
   "source": [
    "plot_stat_map(masker.inverse_transform(speech_results), display_mode='z', threshold=0.05, cut_coords=[-23, -6, 2, 11, 24, 39])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "- Add motion regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
